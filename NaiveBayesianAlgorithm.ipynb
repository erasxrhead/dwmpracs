{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Experiment 4"],"metadata":{"id":"FqkAuDpU3ohO"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0W5PATHZ3FV","executionInfo":{"status":"ok","timestamp":1698942151914,"user_tz":-330,"elapsed":1398,"user":{"displayName":"TEA_134_DEVANSH BHALCHANDRA MAHODAY","userId":"10174106985229978758"}},"outputId":"42cf2296-3b24-4582-f53c-790d4d14893d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Weather : [2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n","Temp : [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n","Play : [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n","[(2, 1), (2, 1), (0, 1), (1, 2), (1, 0), (1, 0), (0, 0), (2, 2), (2, 0), (1, 2), (2, 2), (0, 2), (0, 1), (1, 2)]\n","Predicted Value: [1]\n"]}],"source":["# Assigning features and label variables\n","Weather =  ['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny', 'Rainy','Sunny','Overcast','Overcast','Rainy']\n","Temp =  ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n","Play = ['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n","\n","# Import LabelEncoder\n","from sklearn import preprocessing\n","\n","#creating labelEncoder\n","le = preprocessing.LabelEncoder()\n","\n","# Converting string labels into numbers.\n","weather_encoded = le.fit_transform(Weather)\n","print(\"Weather :\", weather_encoded)\n","\n","# Converting string labels into numbers\n","temp_encoded = le.fit_transform(Temp)\n","label = le.fit_transform(Play)\n","\n","print(\"Temp :\", temp_encoded)\n","print(\"Play :\", label)\n","\n","# Combining weather and temp into single listof tuples\n","features = [tup for tup in zip(weather_encoded, temp_encoded)]\n","print(features)\n","\n","#Import Gaussian Naive Bayes model\n","from sklearn.naive_bayes import GaussianNB\n","\n","#Create a Gaussian Classifier\n","model = GaussianNB()\n","\n","# Train the model using the training sets\n","model.fit(features,label)\n","\n","#Predict Output\n","predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n","print(\"Predicted Value:\", predicted)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"dHcptYHDSSr_"}},{"cell_type":"markdown","source":[],"metadata":{"id":"4KqyUEpKSSpb"}},{"cell_type":"markdown","source":[],"metadata":{"id":"rvPSqqFNSSm0"}},{"cell_type":"markdown","source":[],"metadata":{"id":"DJj3TOGJSSj8"}},{"cell_type":"markdown","source":[],"metadata":{"id":"CL-gJatwSSgD"}},{"cell_type":"markdown","source":[],"metadata":{"id":"wi4qv4LoSScK"}},{"cell_type":"markdown","source":[],"metadata":{"id":"9yvFRWA6SSZV"}},{"cell_type":"markdown","source":[],"metadata":{"id":"gfxbsRfUSSWH"}},{"cell_type":"markdown","source":[],"metadata":{"id":"XNhqvIiKSSSz"}},{"cell_type":"markdown","source":[],"metadata":{"id":"18ZjECvVSSPn"}},{"cell_type":"markdown","source":[],"metadata":{"id":"WG-i107CSSMz"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Dk_lofwRSSKF"}},{"cell_type":"markdown","source":[],"metadata":{"id":"c2HWx-93SSHj"}},{"cell_type":"markdown","source":[],"metadata":{"id":"pNslMQvsSSEr"}},{"cell_type":"markdown","source":[],"metadata":{"id":"zArz3UOdSSBv"}},{"cell_type":"markdown","source":["Naive Bayes classifiers are a collection of classification algorithms based on Bayes’\n","Theorem. It is not a single algorithm but a family of algorithms where all of them share a\n","common principle, i.e. every pair of features being classified is independent of each\n","other. To start with, let us consider a dataset.\n","Consider a fictional dataset that describes the weather conditions for playing a game of golf.\n","Given the weather conditions, each tuple classifies the conditions as fit(“Yes”) or unfit(“No”)\n","for plaing golf.\n","Here is a tabular representation of our dataset."],"metadata":{"id":"Elh-xJ-bSQ_F"}}]}